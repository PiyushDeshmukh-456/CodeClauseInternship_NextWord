{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxXGcKicIzVrQfbONf6t80"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["text = \"\"\"In the realm of technology and artificial intelligence, the word predictor project stands as a testament to innovation. It's all about predicting words. Simple, right? Yet, beneath this simplicity lies a world of complexity and potential. Imagine typing on your smartphone, and as you start to type, the device anticipates what you'll say next. It's not just convenient; it's efficient and almost magical. This project dives deep into the world of Natural Language Processing (NLP) to make this magic happen.\n","\n","NLP, a field at the intersection of computer science and linguistics, is what enables your device to understand and generate human language. It's the technology that powers chatbots, virtual assistants, and even the autocorrect feature on your phone. It's a field that constantly evolves, fueled by large datasets, powerful algorithms, and the quest to make human-computer interactions more seamless.\n","\n","To build an effective word predictor, you need data—lots of it. The more, the better. So, this project starts by collecting vast amounts of text from diverse sources. It could be news articles, books, social media posts, or just about anything with words. This corpus of text serves as the project's playground, the place where the word predictor learns the ropes.\n","\n","But it's not enough to throw text at the predictor and hope for the best. You need to clean it, like panning for gold in a River. Punctuation, special characters, and irrelevant information must be removed, leaving behind only the raw material of language. Once the text is cleaned, it's time to roll up the sleeves and start the training.\n","\n","But wait, there's more to it than just guessing. A good word predictor doesn't just look at the last word you typed; it considers the entire sentence. It's like having a conversation where each word flows naturally from the one before it. So, the model doesn't work in isolation. It uses a technique called 'recurrent' neural networks or fancy transformers that help it keep track of the context.\n","\n","After hours, days, or even weeks of training (depending on the size of your dataset and the power of your computer), the word predictor is ready to show its skills. You type, and it predicts. You pause, and it waits. It's almost like a digital partner in your writing endeavors, suggesting the next word as you compose an email, write a novel, or chat with friends.\n","\n","But there's a twist here. This word predictor isn't just about predicting any word; it's about predicting the right word—the word that fits your writing style, the word that aligns with your thoughts, the word that makes your communication clearer and more efficient. It's about personalization. As you use it more, it gets to know you better. It learns your quirks, your preferences, and your idiosyncrasies.\n","\n","This project isn't just about convenience; it's about empowerment. It's about enabling people to communicate more effectively, whether they're crafting a research paper, sending a heartfelt message, or writing code. A word predictor isn't just a tool; it's a companion in the journey of words.\n","\n","Imagine a future where technology seamlessly blends into our lives, not as a separate entity but as an extension of ourselves. A future where typing becomes a fluid act of thought, where the boundary between human and machine blurs, and where communication is as effortless as thinking. This project is a step in that direction, a step towards a world where words flow freely and where technology is not just smart but also intuitive.\n","\n","As the project evolves, it holds the promise of touching various aspects of our lives. From aiding individuals with disabilities in communication to assisting writers in generating ideas, from making customer service chatbots more responsive to helping students with their essays, the applications are boundless. It's not just about predicting words; it's about transforming how we interact with technology and with each other through the medium of text.\n","\n","In the grand tapestry of technology, this word predictor project represents a thread—one that weaves together the threads of NLP, machine learning, and human ingenuity. It's a testament to what's possible when we combine data, algorithms, and creativity. It's about making technology work for us, not the other way around.\n","\n","So, as you type away on your devices, remember that there's more than meets the eye. Behind those letters and spaces, behind each word you type, there's a world of algorithms and neural networks working tirelessly to make your words count, to make your thoughts flow, and to make your communication a breeze\"\"\""],"metadata":{"id":"fWbaZRbXOwON"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVOOuHOd564-"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n"]},{"cell_type":"code","source":["tokenizer = Tokenizer()"],"metadata":{"id":"To0EMeckgj-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.fit_on_texts([text])"],"metadata":{"id":"QuRgVaVPiQKU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size = len(tokenizer.word_index) + 1"],"metadata":{"id":"Lgp-bEN_BcgV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(tokenizer.word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pqFEDIoVQFAV","executionInfo":{"status":"ok","timestamp":1697006549419,"user_tz":-330,"elapsed":23,"user":{"displayName":"Piyush Deshmukh","userId":"17154441095949171737"}},"outputId":"181af2c5-f327-444c-a4f2-624040fe5322"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["343"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["input_sequences = []\n","for sentence in text.split('\\n'):\n","  tokenized_sentence=tokenizer.texts_to_sequences([sentence])[0]\n","for i in range(1,len(tokenized_sentence)):\n","  input_sequences.append(tokenized_sentence[:i+1])"],"metadata":{"id":"R_wrHQ4BQNEl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","input_sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ww0r2m0uRBCF","executionInfo":{"status":"ok","timestamp":1697006549420,"user_tz":-330,"elapsed":22,"user":{"displayName":"Piyush Deshmukh","userId":"17154441095949171737"}},"outputId":"58d17c14-c841-43f8-bd29-89178634a2d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[44, 10],\n"," [44, 10, 12],\n"," [44, 10, 12, 33],\n"," [44, 10, 12, 33, 332],\n"," [44, 10, 12, 33, 332, 32],\n"," [44, 10, 12, 33, 332, 32, 8],\n"," [44, 10, 12, 33, 332, 32, 8, 333],\n"," [44, 10, 12, 33, 332, 32, 8, 333, 334],\n"," [44, 10, 12, 33, 332, 32, 8, 333, 334, 17],\n"," [44, 10, 12, 33, 332, 32, 8, 333, 334, 17, 36],\n"," [44, 10, 12, 33, 332, 32, 8, 333, 334, 17, 36, 18],\n"," [44, 10, 12, 33, 332, 32, 8, 333, 334, 17, 36, 18, 72],\n"," [44, 10, 12, 33, 332, 32, 8, 333, 334, 17, 36, 18, 72, 335],\n"," [44, 10, 12, 33, 332, 32, 8, 333, 334, 17, 36, 18, 72, 335, 1],\n"," [44, 10, 12, 33, 332, 32, 8, 333, 334, 17, 36, 18, 72, 335, 1, 336],\n"," [44, 10, 12, 33, 332, 32, 8, 333, 334, 17, 36, 18, 72, 335, 1, 336, 47],\n"," [44, 10, 12, 33, 332, 32, 8, 333, 334, 17, 36, 18, 72, 335, 1, 336, 47, 337],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342,\n","  5],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342,\n","  5,\n","  26],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342,\n","  5,\n","  26,\n","  8],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342,\n","  5,\n","  26,\n","  8,\n","  77],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342,\n","  5,\n","  26,\n","  8,\n","  77,\n","  83],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342,\n","  5,\n","  26,\n","  8,\n","  77,\n","  83,\n","  3],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342,\n","  5,\n","  26,\n","  8,\n","  77,\n","  83,\n","  3,\n","  5],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342,\n","  5,\n","  26,\n","  8,\n","  77,\n","  83,\n","  3,\n","  5,\n","  26],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342,\n","  5,\n","  26,\n","  8,\n","  77,\n","  83,\n","  3,\n","  5,\n","  26,\n","  8],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342,\n","  5,\n","  26,\n","  8,\n","  77,\n","  83,\n","  3,\n","  5,\n","  26,\n","  8,\n","  37],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342,\n","  5,\n","  26,\n","  8,\n","  77,\n","  83,\n","  3,\n","  5,\n","  26,\n","  8,\n","  37,\n","  2],\n"," [44,\n","  10,\n","  12,\n","  33,\n","  332,\n","  32,\n","  8,\n","  333,\n","  334,\n","  17,\n","  36,\n","  18,\n","  72,\n","  335,\n","  1,\n","  336,\n","  47,\n","  337,\n","  338,\n","  3,\n","  339,\n","  47,\n","  48,\n","  7,\n","  12,\n","  33,\n","  36,\n","  2,\n","  31,\n","  4,\n","  42,\n","  3,\n","  75,\n","  76,\n","  340,\n","  341,\n","  5,\n","  26,\n","  8,\n","  23,\n","  342,\n","  5,\n","  26,\n","  8,\n","  77,\n","  83,\n","  3,\n","  5,\n","  26,\n","  8,\n","  37,\n","  2,\n","  343]]"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["\n","# finding the longest sentence to arrnge the input data equally\n","max_len =max([len(x) for x in input_sequences])"],"metadata":{"id":"uuZa3wz8T216"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_len"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1J7xHHYngmP","executionInfo":{"status":"ok","timestamp":1697006549420,"user_tz":-330,"elapsed":19,"user":{"displayName":"Piyush Deshmukh","userId":"17154441095949171737"}},"outputId":"352a5307-092e-4e4a-af50-3e4d7446f2a0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["53"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"],"metadata":{"id":"Oq-wTKNYsR2h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["padded_input_sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HPlgC2uBvj1E","executionInfo":{"status":"ok","timestamp":1697006550114,"user_tz":-330,"elapsed":17,"user":{"displayName":"Piyush Deshmukh","userId":"17154441095949171737"}},"outputId":"7f041cc5-e927-48fb-e1bf-c4ba10227f3d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  0,   0,   0, ...,   0,  44,  10],\n","       [  0,   0,   0, ...,  44,  10,  12],\n","       [  0,   0,   0, ...,  10,  12,  33],\n","       ...,\n","       [  0,   0,  44, ...,  26,   8,  37],\n","       [  0,  44,  10, ...,   8,  37,   2],\n","       [ 44,  10,  12, ...,  37,   2, 343]], dtype=int32)"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["X = padded_input_sequences[:,:-1]\n","Y = padded_input_sequences[:,-1]"],"metadata":{"id":"ngkiVNSOvmFx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.utils import to_categorical\n","Y=to_categorical(Y,num_classes=344)"],"metadata":{"id":"FaLHgLPWkh5B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jRtTxqPoUhUa","executionInfo":{"status":"ok","timestamp":1697006551309,"user_tz":-330,"elapsed":1208,"user":{"displayName":"Piyush Deshmukh","userId":"17154441095949171737"}},"outputId":"83d2ac69-5cc8-498f-8407-488749d075e2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(52, 344)"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense"],"metadata":{"id":"qY34vV2GWWu_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''model=Sequential()\n","model.add(Embedding(283,100,input_length=56))\n","model.add(LSTM(150))\n","model.add(Dense(283,activation='softmax'))'''\n","model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=100, input_length=max_len - 1))\n","model.add(tf.keras.layers.LSTM(150))\n","model.add(tf.keras.layers.Dense(vocab_size, activation='softmax'))"],"metadata":{"id":"5lmre_JsXyO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F39tZsHaaHDB","executionInfo":{"status":"ok","timestamp":1697006551310,"user_tz":-330,"elapsed":10,"user":{"displayName":"Piyush Deshmukh","userId":"17154441095949171737"}},"outputId":"eb710438-190c-42d7-9522-39cd03768c7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 52, 100)           34400     \n","                                                                 \n"," lstm_1 (LSTM)               (None, 150)               150600    \n","                                                                 \n"," dense_1 (Dense)             (None, 344)               51944     \n","                                                                 \n","=================================================================\n","Total params: 236944 (925.56 KB)\n","Trainable params: 236944 (925.56 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.fit(X,Y,epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JlbAWGRHpuT2","executionInfo":{"status":"ok","timestamp":1697006811243,"user_tz":-330,"elapsed":21486,"user":{"displayName":"Piyush Deshmukh","userId":"17154441095949171737"}},"outputId":"10c2c6cb-5851-4175-a5a5-dc9db686b4ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","2/2 [==============================] - 0s 71ms/step - loss: 1.9499 - accuracy: 0.6923\n","Epoch 2/100\n","2/2 [==============================] - 0s 74ms/step - loss: 1.9195 - accuracy: 0.6923\n","Epoch 3/100\n","2/2 [==============================] - 0s 69ms/step - loss: 1.8970 - accuracy: 0.7115\n","Epoch 4/100\n","2/2 [==============================] - 0s 72ms/step - loss: 1.8713 - accuracy: 0.7500\n","Epoch 5/100\n","2/2 [==============================] - 0s 81ms/step - loss: 1.8431 - accuracy: 0.7500\n","Epoch 6/100\n","2/2 [==============================] - 0s 74ms/step - loss: 1.8169 - accuracy: 0.7500\n","Epoch 7/100\n","2/2 [==============================] - 0s 69ms/step - loss: 1.7917 - accuracy: 0.7692\n","Epoch 8/100\n","2/2 [==============================] - 0s 73ms/step - loss: 1.7678 - accuracy: 0.8077\n","Epoch 9/100\n","2/2 [==============================] - 0s 70ms/step - loss: 1.7405 - accuracy: 0.8077\n","Epoch 10/100\n","2/2 [==============================] - 0s 68ms/step - loss: 1.7158 - accuracy: 0.8077\n","Epoch 11/100\n","2/2 [==============================] - 0s 70ms/step - loss: 1.6875 - accuracy: 0.8077\n","Epoch 12/100\n","2/2 [==============================] - 0s 70ms/step - loss: 1.6637 - accuracy: 0.8077\n","Epoch 13/100\n","2/2 [==============================] - 0s 87ms/step - loss: 1.6391 - accuracy: 0.8462\n","Epoch 14/100\n","2/2 [==============================] - 0s 71ms/step - loss: 1.6132 - accuracy: 0.8654\n","Epoch 15/100\n","2/2 [==============================] - 0s 71ms/step - loss: 1.5893 - accuracy: 0.8654\n","Epoch 16/100\n","2/2 [==============================] - 0s 72ms/step - loss: 1.5598 - accuracy: 0.8654\n","Epoch 17/100\n","2/2 [==============================] - 0s 70ms/step - loss: 1.5358 - accuracy: 0.8654\n","Epoch 18/100\n","2/2 [==============================] - 0s 80ms/step - loss: 1.5112 - accuracy: 0.8462\n","Epoch 19/100\n","2/2 [==============================] - 0s 70ms/step - loss: 1.4840 - accuracy: 0.8846\n","Epoch 20/100\n","2/2 [==============================] - 0s 79ms/step - loss: 1.4634 - accuracy: 0.9038\n","Epoch 21/100\n","2/2 [==============================] - 0s 72ms/step - loss: 1.4336 - accuracy: 0.9038\n","Epoch 22/100\n","2/2 [==============================] - 0s 69ms/step - loss: 1.4127 - accuracy: 0.9038\n","Epoch 23/100\n","2/2 [==============================] - 0s 66ms/step - loss: 1.3840 - accuracy: 0.9038\n","Epoch 24/100\n","2/2 [==============================] - 0s 69ms/step - loss: 1.3604 - accuracy: 0.9423\n","Epoch 25/100\n","2/2 [==============================] - 0s 70ms/step - loss: 1.3384 - accuracy: 0.9231\n","Epoch 26/100\n","2/2 [==============================] - 0s 68ms/step - loss: 1.3089 - accuracy: 0.9423\n","Epoch 27/100\n","2/2 [==============================] - 0s 75ms/step - loss: 1.2872 - accuracy: 0.9615\n","Epoch 28/100\n","2/2 [==============================] - 0s 84ms/step - loss: 1.2630 - accuracy: 0.9615\n","Epoch 29/100\n","2/2 [==============================] - 0s 78ms/step - loss: 1.2401 - accuracy: 0.9615\n","Epoch 30/100\n","2/2 [==============================] - 0s 74ms/step - loss: 1.2148 - accuracy: 0.9615\n","Epoch 31/100\n","2/2 [==============================] - 0s 74ms/step - loss: 1.1928 - accuracy: 0.9615\n","Epoch 32/100\n","2/2 [==============================] - 0s 84ms/step - loss: 1.1696 - accuracy: 0.9423\n","Epoch 33/100\n","2/2 [==============================] - 0s 70ms/step - loss: 1.1461 - accuracy: 0.9615\n","Epoch 34/100\n","2/2 [==============================] - 0s 67ms/step - loss: 1.1229 - accuracy: 0.9615\n","Epoch 35/100\n","2/2 [==============================] - 0s 81ms/step - loss: 1.1007 - accuracy: 0.9615\n","Epoch 36/100\n","2/2 [==============================] - 0s 71ms/step - loss: 1.0779 - accuracy: 0.9808\n","Epoch 37/100\n","2/2 [==============================] - 0s 73ms/step - loss: 1.0560 - accuracy: 0.9808\n","Epoch 38/100\n","2/2 [==============================] - 0s 70ms/step - loss: 1.0340 - accuracy: 0.9808\n","Epoch 39/100\n","2/2 [==============================] - 0s 70ms/step - loss: 1.0132 - accuracy: 0.9808\n","Epoch 40/100\n","2/2 [==============================] - 0s 72ms/step - loss: 0.9923 - accuracy: 0.9808\n","Epoch 41/100\n","2/2 [==============================] - 0s 70ms/step - loss: 0.9709 - accuracy: 0.9808\n","Epoch 42/100\n","2/2 [==============================] - 0s 72ms/step - loss: 0.9492 - accuracy: 0.9808\n","Epoch 43/100\n","2/2 [==============================] - 0s 75ms/step - loss: 0.9294 - accuracy: 0.9808\n","Epoch 44/100\n","2/2 [==============================] - 0s 72ms/step - loss: 0.9097 - accuracy: 1.0000\n","Epoch 45/100\n","2/2 [==============================] - 0s 72ms/step - loss: 0.8898 - accuracy: 1.0000\n","Epoch 46/100\n","2/2 [==============================] - 0s 69ms/step - loss: 0.8702 - accuracy: 1.0000\n","Epoch 47/100\n","2/2 [==============================] - 0s 70ms/step - loss: 0.8539 - accuracy: 1.0000\n","Epoch 48/100\n","2/2 [==============================] - 0s 75ms/step - loss: 0.8343 - accuracy: 1.0000\n","Epoch 49/100\n","2/2 [==============================] - 0s 70ms/step - loss: 0.8161 - accuracy: 1.0000\n","Epoch 50/100\n","2/2 [==============================] - 0s 71ms/step - loss: 0.7988 - accuracy: 1.0000\n","Epoch 51/100\n","2/2 [==============================] - 0s 72ms/step - loss: 0.7813 - accuracy: 1.0000\n","Epoch 52/100\n","2/2 [==============================] - 0s 69ms/step - loss: 0.7634 - accuracy: 1.0000\n","Epoch 53/100\n","2/2 [==============================] - 0s 69ms/step - loss: 0.7475 - accuracy: 1.0000\n","Epoch 54/100\n","2/2 [==============================] - 0s 73ms/step - loss: 0.7309 - accuracy: 1.0000\n","Epoch 55/100\n","2/2 [==============================] - 0s 124ms/step - loss: 0.7139 - accuracy: 1.0000\n","Epoch 56/100\n","2/2 [==============================] - 0s 126ms/step - loss: 0.6990 - accuracy: 1.0000\n","Epoch 57/100\n","2/2 [==============================] - 0s 136ms/step - loss: 0.6835 - accuracy: 1.0000\n","Epoch 58/100\n","2/2 [==============================] - 0s 130ms/step - loss: 0.6680 - accuracy: 1.0000\n","Epoch 59/100\n","2/2 [==============================] - 0s 127ms/step - loss: 0.6541 - accuracy: 1.0000\n","Epoch 60/100\n","2/2 [==============================] - 0s 133ms/step - loss: 0.6390 - accuracy: 1.0000\n","Epoch 61/100\n","2/2 [==============================] - 0s 133ms/step - loss: 0.6251 - accuracy: 1.0000\n","Epoch 62/100\n","2/2 [==============================] - 0s 141ms/step - loss: 0.6119 - accuracy: 1.0000\n","Epoch 63/100\n","2/2 [==============================] - 0s 125ms/step - loss: 0.5984 - accuracy: 1.0000\n","Epoch 64/100\n","2/2 [==============================] - 0s 72ms/step - loss: 0.5852 - accuracy: 1.0000\n","Epoch 65/100\n","2/2 [==============================] - 0s 72ms/step - loss: 0.5732 - accuracy: 1.0000\n","Epoch 66/100\n","2/2 [==============================] - 0s 71ms/step - loss: 0.5607 - accuracy: 1.0000\n","Epoch 67/100\n","2/2 [==============================] - 0s 72ms/step - loss: 0.5483 - accuracy: 1.0000\n","Epoch 68/100\n","2/2 [==============================] - 0s 69ms/step - loss: 0.5363 - accuracy: 1.0000\n","Epoch 69/100\n","2/2 [==============================] - 0s 68ms/step - loss: 0.5257 - accuracy: 1.0000\n","Epoch 70/100\n","2/2 [==============================] - 0s 67ms/step - loss: 0.5146 - accuracy: 1.0000\n","Epoch 71/100\n","2/2 [==============================] - 0s 70ms/step - loss: 0.5044 - accuracy: 1.0000\n","Epoch 72/100\n","2/2 [==============================] - 0s 73ms/step - loss: 0.4935 - accuracy: 1.0000\n","Epoch 73/100\n","2/2 [==============================] - 0s 77ms/step - loss: 0.4836 - accuracy: 1.0000\n","Epoch 74/100\n","2/2 [==============================] - 0s 79ms/step - loss: 0.4744 - accuracy: 1.0000\n","Epoch 75/100\n","2/2 [==============================] - 0s 68ms/step - loss: 0.4640 - accuracy: 1.0000\n","Epoch 76/100\n","2/2 [==============================] - 0s 68ms/step - loss: 0.4552 - accuracy: 1.0000\n","Epoch 77/100\n","2/2 [==============================] - 0s 73ms/step - loss: 0.4462 - accuracy: 1.0000\n","Epoch 78/100\n","2/2 [==============================] - 0s 67ms/step - loss: 0.4374 - accuracy: 1.0000\n","Epoch 79/100\n","2/2 [==============================] - 0s 74ms/step - loss: 0.4283 - accuracy: 1.0000\n","Epoch 80/100\n","2/2 [==============================] - 0s 84ms/step - loss: 0.4202 - accuracy: 1.0000\n","Epoch 81/100\n","2/2 [==============================] - 0s 73ms/step - loss: 0.4116 - accuracy: 1.0000\n","Epoch 82/100\n","2/2 [==============================] - 0s 75ms/step - loss: 0.4038 - accuracy: 1.0000\n","Epoch 83/100\n","2/2 [==============================] - 0s 68ms/step - loss: 0.3958 - accuracy: 1.0000\n","Epoch 84/100\n","2/2 [==============================] - 0s 71ms/step - loss: 0.3884 - accuracy: 1.0000\n","Epoch 85/100\n","2/2 [==============================] - 0s 71ms/step - loss: 0.3812 - accuracy: 1.0000\n","Epoch 86/100\n","2/2 [==============================] - 0s 69ms/step - loss: 0.3747 - accuracy: 1.0000\n","Epoch 87/100\n","2/2 [==============================] - 0s 74ms/step - loss: 0.3678 - accuracy: 1.0000\n","Epoch 88/100\n","2/2 [==============================] - 0s 67ms/step - loss: 0.3610 - accuracy: 1.0000\n","Epoch 89/100\n","2/2 [==============================] - 0s 69ms/step - loss: 0.3544 - accuracy: 1.0000\n","Epoch 90/100\n","2/2 [==============================] - 0s 71ms/step - loss: 0.3484 - accuracy: 1.0000\n","Epoch 91/100\n","2/2 [==============================] - 0s 71ms/step - loss: 0.3421 - accuracy: 1.0000\n","Epoch 92/100\n","2/2 [==============================] - 0s 66ms/step - loss: 0.3359 - accuracy: 1.0000\n","Epoch 93/100\n","2/2 [==============================] - 0s 81ms/step - loss: 0.3300 - accuracy: 1.0000\n","Epoch 94/100\n","2/2 [==============================] - 0s 71ms/step - loss: 0.3244 - accuracy: 1.0000\n","Epoch 95/100\n","2/2 [==============================] - 0s 69ms/step - loss: 0.3194 - accuracy: 1.0000\n","Epoch 96/100\n","2/2 [==============================] - 0s 72ms/step - loss: 0.3140 - accuracy: 1.0000\n","Epoch 97/100\n","2/2 [==============================] - 0s 70ms/step - loss: 0.3086 - accuracy: 1.0000\n","Epoch 98/100\n","2/2 [==============================] - 0s 77ms/step - loss: 0.3039 - accuracy: 1.0000\n","Epoch 99/100\n","2/2 [==============================] - 0s 76ms/step - loss: 0.2988 - accuracy: 1.0000\n","Epoch 100/100\n","2/2 [==============================] - 0s 74ms/step - loss: 0.2935 - accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a72d7fd7df0>"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["import time\n","import numpy as np\n","text = 'text'\n","for i in range(6):\n","  token_text = tokenizer.texts_to_sequences([text])[0]\n","  padded_token_text = pad_sequences([token_text], maxlen=52, padding='pre')\n","  pos = np.argmax(model.predict(padded_token_text))\n","  for word,index in tokenizer.word_index.items():\n","    if index == pos:\n","      text=text + \" \" + word\n","      print(text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SpPYuwH-wpQk","executionInfo":{"status":"ok","timestamp":1697006823579,"user_tz":-330,"elapsed":2466,"user":{"displayName":"Piyush Deshmukh","userId":"17154441095949171737"}},"outputId":"db78fe9b-f4eb-4da9-8e50-e2c547e39a92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 37ms/step\n","text away\n","1/1 [==============================] - 0s 99ms/step\n","text away on\n","1/1 [==============================] - 0s 39ms/step\n","text away on your\n","1/1 [==============================] - 0s 28ms/step\n","text away on your devices\n","1/1 [==============================] - 0s 25ms/step\n","text away on your devices remember\n","1/1 [==============================] - 0s 29ms/step\n","text away on your devices remember that\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Qppurh6Y58yU"},"execution_count":null,"outputs":[]}]}